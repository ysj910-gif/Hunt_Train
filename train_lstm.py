import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import tkinter as tk
from tkinter import filedialog
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
import os
import json

# === [1] ëª¨ë¸ í´ë˜ìŠ¤ ===
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, future_steps=1, dropout=0.3):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.future_steps = future_steps
        self.num_classes = num_classes
        
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        self.fc = nn.Linear(hidden_size, num_classes * future_steps)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out.reshape(-1, self.future_steps, self.num_classes)

# === [2] ì„¤ì • ===
SEQ_LENGTH = 10
FUTURE_STEPS = 5
HIDDEN_SIZE = 256
NUM_LAYERS = 3
DROPOUT = 0.3
BATCH_SIZE = 64
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
GAMMA = 0.90

# ëª©í‘œ ì—í¬í¬ (ë„‰ë„‰í•˜ê²Œ)
TARGET_EPOCHS = 1000 

FEATURE_COLS = [
    'player_x', 'player_y', 
    'delta_x', 'delta_y',   # <--- [ì‹ ê·œ ì¶”ê°€] ì†ë„ ì •ë³´
    'entropy', 'platform_id', 'ult_ready', 'sub_ready',
    'inv_dist_up', 'inv_dist_down', 'inv_dist_left', 'inv_dist_right',
    'corner_tl', 'corner_tr', 'corner_bl', 'corner_br'
]
TARGET_COL = 'key_pressed'
SAVE_PATH = "kinesis_lstm_best.pth"

# === [3] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===
def load_install_skills():
    config_path = "hunter_config.json"
    install_skills = {}
    if not os.path.exists(config_path): return {}
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            mapping = data.get("mapping", {})
            for name, info in mapping.items():
                key = info.get("key", "").lower()
                dur = float(info.get("dur", 0))
                if key and dur >= 2.0:
                    install_skills[key] = dur
        return install_skills
    except: return {}

def calculate_smart_rewards(df, install_skills, gamma=0.98):
    timestamps = df['timestamp'].values
    actions = df['key_pressed'].fillna('None').astype(str).values
    
    if 'kill_reward' not in df.columns:
        if 'kill_count' in df.columns:
            rewards = df['kill_count'].diff().fillna(0).values
            rewards[rewards < 0] = 0
        else:
            rewards = np.zeros(len(df))
    else:
        rewards = df['kill_reward'].values

    discounted = np.zeros_like(rewards, dtype=np.float32)
    running_add = 0
    for t in reversed(range(len(rewards))):
        if rewards[t] > 0: running_add = rewards[t]
        else: running_add = running_add * gamma
        discounted[t] = running_add

    if install_skills:
        for t in range(len(df)):
            action = actions[t].lower()
            matched_dur = 0
            for k, dur in install_skills.items():
                if k in action: matched_dur = dur; break
            
            if matched_dur > 0:
                current_time = timestamps[t]
                future_kills = 0
                for future_t in range(t + 1, len(df)):
                    if timestamps[future_t] - current_time > matched_dur: break
                    future_kills += rewards[future_t]
                
                if future_kills >= 3: discounted[t] += future_kills * 3.0
                else: discounted[t] -= 5.0
    
    df['discounted_reward'] = discounted
    return df

def create_sequences_smart(df, seq_length, future_steps, scaler, encoder):
    # 1. ê¸°ë³¸ ë°ì´í„° ì²˜ë¦¬
    for col in FEATURE_COLS:
        if col not in df.columns: df[col] = 0
            
    # ì •ê·œí™” (Scaler)
    data_scaled = scaler.transform(df[FEATURE_COLS])
    target_values = encoder.transform(df[TARGET_COL].astype(str).values)
    values = df['discounted_reward'].values
    
    xs, ys = [], []
    
    # 2. ì‹œí€€ìŠ¤ ìƒì„± (ê¸°ì¡´)
    for i in range(len(df) - seq_length - future_steps + 1):
        if values[i + seq_length] <= 0.01 and np.random.rand() > 0.1: continue
        
        x_window = data_scaled[i : i + seq_length]
        y_window = target_values[i + seq_length : i + seq_length + future_steps]
        
        xs.append(x_window)
        ys.append(y_window)

        # [â˜…ì‹ ê·œ] 3. ë°ì´í„° ì¦ê°• (ì¢Œìš° ë°˜ì „)
        # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „ ë°ì´í„°ë¥¼ ì¶”ê°€ í•™ìŠµ (ë°ì´í„° 1.5ë°° ë»¥íŠ€ê¸° íš¨ê³¼)
        if np.random.rand() < 0.5:
            # ë³µì‚¬ë³¸ ìƒì„±
            x_aug = x_window.copy()
            
            # FEATURE_COLS ìˆœì„œì— ë§ì¶°ì„œ ì¢Œìš° ê´€ë ¨ ë³€ìˆ˜ ë°˜ì „
            # ì˜ˆ: delta_x(ì†ë„) ë°˜ì „, dist_left <-> dist_right êµì²´ ë“±
            # (ë‹¨, Scalerê°€ ì ìš©ëœ ìƒíƒœë¼ ë‹¨ìˆœ -1 ê³±í•˜ê¸°ëŠ” ìœ„í—˜í•  ìˆ˜ ìˆìŒ)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ 'delta_x'ë§Œ ë¶€í˜¸ë¥¼ ë’¤ì§‘ëŠ” ë°©ì‹ìœ¼ë¡œ ë…¸ì´ì¦ˆë¥¼ ì¤ë‹ˆë‹¤.
            
            # delta_xê°€ 2ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤ 2)ì´ë¼ê³  ê°€ì •
            try:
                dx_idx = FEATURE_COLS.index('delta_x')
                x_aug[:, dx_idx] *= -1 # ì†ë„ ë°˜ì „
            except: pass
            
            xs.append(x_aug)
            ys.append(y_window) # ì •ë‹µ(í–‰ë™)ì€ ê·¸ëŒ€ë¡œ (ë˜ëŠ” í–‰ë™ë„ ë°˜ì „ì‹œì¼œì•¼ ì™„ë²½í•˜ì§€ë§Œ ë³µì¡í•¨)

    return np.array(xs), np.array(ys)

# === [4] ë©”ì¸ í•™ìŠµ í•¨ìˆ˜ (ì•ˆì „ì¥ì¹˜ ì¶”ê°€) ===
def train():
    root = tk.Tk(); root.withdraw()
    install_skills = load_install_skills()
    
    # 1. ì´ì–´í•˜ê¸° ì—¬ë¶€ í™•ì¸
    start_epoch = 0
    resume_mode = False
    best_acc = 0.0
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ë³€ìˆ˜ë“¤
    loaded_state = None
    loaded_scaler = None
    loaded_encoder = None
    
    if os.path.exists(SAVE_PATH):
        ans = input(f"\nğŸ’¾ ê¸°ì¡´ ëª¨ë¸({SAVE_PATH}) ë°œê²¬! ì´ì–´ì„œ í•™ìŠµí• ê¹Œìš”? (y/n): ").strip().lower()
        if ans == 'y':
            print("ğŸ”„ ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
            try:
                checkpoint = torch.load(SAVE_PATH, map_location=DEVICE)
                loaded_state = checkpoint['model_state']
                loaded_scaler = checkpoint['scaler']
                loaded_encoder = checkpoint['encoder']
                
                if 'epoch' in checkpoint:
                    start_epoch = checkpoint['epoch'] + 1
                    best_acc = checkpoint.get('best_acc', 0.0)
                    print(f"âœ… Epoch {start_epoch}ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤. (ê¸°ì¡´ ìµœê³  ì •í™•ë„: {best_acc:.2f}%)")
                else:
                    print("âš ï¸ ì´ì „ íŒŒì¼ì— Epoch ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    user_epoch = input("   ë§ˆì§€ë§‰ìœ¼ë¡œ ì™„ë£Œí•œ Epoch ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 300): ")
                    start_epoch = int(user_epoch) if user_epoch.isdigit() else 0
                
                resume_mode = True
            except Exception as e:
                print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\n   -> ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                resume_mode = False

    # 2. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ í•™ìŠµí•  CSV ë°ì´í„° íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”...")
    files = filedialog.askopenfilenames(title="CSV ì„ íƒ", filetypes=[("CSV", "*.csv")])
    if not files: return

    print("â³ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    temp_dfs = []
    for f in files:
        try:
            df = pd.read_csv(f)
            ignore_keys = ['media_volume_up', 'esc', 'f1', 'alt_l', 'caps_lock', 'unknown']
            df = df[~df['key_pressed'].isin(ignore_keys)]
            df['key_pressed'] = df['key_pressed'].fillna('None')
            df['platform_id'] = df['platform_id'].fillna(-1)
            
            if 'kill_reward' not in df.columns and 'kill_count' in df.columns:
                df['kill_reward'] = df['kill_count'].diff().fillna(0)
                df.loc[df['kill_reward'] < 0, 'kill_reward'] = 0
            
            df = calculate_smart_rewards(df, install_skills, gamma=GAMMA)
            temp_dfs.append(df)
        except: pass
            
    if not temp_dfs: return
    full_df = pd.concat(temp_dfs, ignore_index=True)
    
    # 3. Scaler & Encoder ì„¤ì •
    if resume_mode and loaded_scaler and loaded_encoder:
        print("ğŸ”— ê¸°ì¡´ ëª¨ë¸ì˜ Scalerì™€ Encoderë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        scaler = loaded_scaler
        encoder = loaded_encoder
    else:
        print("ğŸ†• ìƒˆë¡œìš´ Scalerì™€ Encoderë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.")
        scaler = StandardScaler()
        scaler.fit(full_df[FEATURE_COLS])
        encoder = LabelEncoder()
        encoder.fit(full_df[TARGET_COL].astype(str))
    
    num_classes = len(encoder.classes_)

    # 4. ì‹œí€€ìŠ¤ ìƒì„±
    print(f"âœ‚ï¸ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
    X_list, y_list = [], []
    for df in temp_dfs:
        xs, ys = create_sequences_smart(df, SEQ_LENGTH, FUTURE_STEPS, scaler, encoder)
        if len(xs) > 0:
            X_list.append(xs)
            y_list.append(ys)
            
    if not X_list: print("âŒ ë°ì´í„° ë¶€ì¡±"); return
    X_all = np.concatenate(X_list, axis=0)
    y_all = np.concatenate(y_list, axis=0)
    print(f"âœ¨ ì´ {len(X_all)}ê°œ ì‹œí€€ìŠ¤ë¡œ í•™ìŠµ ì§„í–‰")

    # 5. ë°ì´í„°ì…‹ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, shuffle=True)
    train_dataset = TensorDataset(torch.FloatTensor(X_train).to(DEVICE), torch.LongTensor(y_train).to(DEVICE))
    test_dataset = TensorDataset(torch.FloatTensor(X_test).to(DEVICE), torch.LongTensor(y_test).to(DEVICE))
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # 6. ëª¨ë¸ ì´ˆê¸°í™”
    model = LSTMModel(len(FEATURE_COLS), HIDDEN_SIZE, NUM_LAYERS, num_classes, FUTURE_STEPS, DROPOUT).to(DEVICE)
    if resume_mode and loaded_state:
        try:
            model.load_state_dict(loaded_state)
            print("âœ… ê¸°ì¡´ í•™ìŠµ ê°€ì¤‘ì¹˜ ë³µì› ì™„ë£Œ!")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ êµ¬ì¡° ë¶ˆì¼ì¹˜, ì²˜ìŒë¶€í„° ì‹œì‘: {e}")
            start_epoch = 0; best_acc = 0.0; resume_mode = False

    # 7. Optimizer & Learning Rate (í•µì‹¬ ìˆ˜ì •!)
    # ì¬í•™ìŠµ(Resume) ì‹œì—ëŠ” LRì„ 0.0001ë¡œ ë‚®ì¶¤ (ê¸°ì¡´ 0.001)
    initial_lr = 0.001
    if resume_mode:
        initial_lr = 0.0001 
        print(f"ğŸ“‰ ì¬í•™ìŠµ ëª¨ë“œ: í•™ìŠµë¥ ì„ {initial_lr}ë¡œ ë‚®ì¶°ì„œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤ (ì‡¼í¬ ë°©ì§€).")
    
    # Class Weight ì ìš©
    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_all.flatten()), y=y_all.flatten())
    try:
        none_idx = encoder.transform(['None'])[0]
        class_weights[none_idx] *= 0.1 
    except: pass
    
    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(DEVICE))
    optimizer = optim.Adam(model.parameters(), lr=initial_lr)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬: ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ë„ë¡ ìˆ˜ì •
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)

    # 8. í•™ìŠµ ë£¨í”„
    print(f"\nğŸ”¥ í•™ìŠµ ì‹œì‘: Epoch {start_epoch+1} ~ {TARGET_EPOCHS}")
    best_model_state = model.state_dict() if resume_mode else None
    
    for epoch in range(start_epoch, TARGET_EPOCHS):
        model.train()
        train_loss = 0
        for bx, by in train_loader:
            optimizer.zero_grad()
            outputs = model(bx)
            loss = criterion(outputs.view(-1, num_classes), by.view(-1))
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            train_loss += loss.item()
            
        model.eval()
        correct = 0; total = 0
        with torch.no_grad():
            for bx, by in test_loader:
                outputs = model(bx)
                _, predicted = torch.max(outputs, 2)
                correct += (predicted == by).sum().item()
                total += by.numel()
        
        acc = 100 * correct / total
        avg_loss = train_loss / len(train_loader)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ (UserWarning í•´ê²°)
        scheduler.step(acc)

        if acc > best_acc:
            best_acc = acc
            best_model_state = model.state_dict()
            print(f"Epoch {epoch+1}/{TARGET_EPOCHS} | Loss: {avg_loss:.4f} | Acc: {acc:.2f}% (â­ New Best!)")
            
            torch.save({
                'epoch': epoch,
                'model_state': best_model_state,
                'best_acc': best_acc,
                'scaler': scaler, 'encoder': encoder,
                'feature_cols': FEATURE_COLS,
                'input_size': len(FEATURE_COLS), 'hidden_size': HIDDEN_SIZE,
                'num_layers': NUM_LAYERS, 'num_classes': num_classes,
                'seq_length': SEQ_LENGTH, 'future_steps': FUTURE_STEPS, 'dropout': DROPOUT
            }, SAVE_PATH)
            
        elif (epoch+1) % 5 == 0:
            print(f"Epoch {epoch+1}/{TARGET_EPOCHS} | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%")

    print(f"âœ… ìµœì¢… ì™„ë£Œ! ìµœê³  ì •í™•ë„: {best_acc:.2f}%")

if __name__ == "__main__":
    train()