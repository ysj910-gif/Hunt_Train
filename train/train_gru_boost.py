import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import multiprocessing

# ---------------------------------------------------------
# ğŸš€ RTX 4070 Super ì„±ëŠ¥ ìµœì í™” ì„¤ì •
# ---------------------------------------------------------
# ë°°ì¹˜ ì‚¬ì´ì¦ˆ: 64 -> 2048 (VRAM ë¹µë¹µí•˜ë‹ˆê¹Œ í¬ê²Œ ì¡ì•„ì„œ GPU ê°ˆêµ¬ê¸°)
BATCH_SIZE = 2048  
# ë°ì´í„° ë¡œë” ë³‘ë ¬ ì²˜ë¦¬: CPU ì½”ì–´ í™œìš© (ë³´í†µ ì½”ì–´ ìˆ˜ì˜ ì ˆë°˜)
NUM_WORKERS = min(8, multiprocessing.cpu_count())
# í˜¼í•© ì •ë°€ë„(FP16): í…ì„œ ì½”ì–´ í™œìš© (ì†ë„ 2ë°°, ë©”ëª¨ë¦¬ ì ˆì•½)
USE_AMP = True 

# í•™ìŠµ ì„¤ì •
SEQ_LENGTH = 10
EPOCHS = 300       # ì†ë„ê°€ ë¹ ë¥´ë‹ˆ ì—í­ì„ ëŠ˜ë ¤ë„ ë¨
LEARNING_RATE = 0.002 # ë°°ì¹˜ê°€ ì»¤ì§€ë©´ í•™ìŠµë¥ ë„ ì‚´ì§ ì˜¬ë ¤ì•¼ í•¨
PATIENCE = 20
MODEL_SAVE_PATH = "best_gru_model_boost.pth"

# ---------------------------------------------------------

from modules.model import LSTMModel 

FEATURE_COLS = [
    'player_x', 'player_y', 'delta_x', 'delta_y', 
    'entropy', 'platform_id', 'ult_ready', 'sub_ready', 
    'inv_dist_up', 'inv_dist_down', 'inv_dist_left', 'inv_dist_right', 
    'corner_tl', 'corner_tr', 'corner_bl', 'corner_br'
]

# CuDNN ë²¤ì¹˜ë§ˆí‚¹ í™œì„±í™” (ê³ ì •ëœ ì…ë ¥ í¬ê¸°ì—ì„œ ì†ë„ ìµœì í™”)
torch.backends.cudnn.benchmark = True

class MapleDataset(Dataset):
    def __init__(self, sequences, labels):
        self.sequences = torch.FloatTensor(sequences)
        self.labels = torch.LongTensor(labels)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return self.sequences[idx], self.labels[idx]

def create_sequences(data, labels, seq_length):
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i : i+seq_length]
        y = labels[i+seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

def train():
    print(f"ğŸš€ High-Performance Training Mode")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Batch Size: {BATCH_SIZE} | Workers: {NUM_WORKERS} | AMP: {USE_AMP}")
    
    # 1. ë°ì´í„° ë¡œë“œ
    files = glob.glob("upgraded_*.csv")
    if not files:
        print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_list = []
    print("ğŸ“‚ CSV íŒŒì¼ ë¡œë”© ì¤‘...")
    for f in tqdm(files):
        try:
            d = pd.read_csv(f)
            if all(col in d.columns for col in FEATURE_COLS) and 'key_pressed' in d.columns:
                df_list.append(d)
        except: pass
    
    full_df = pd.concat(df_list, ignore_index=True).fillna(0)
    print(f"âœ… ì´ ë°ì´í„°: {len(full_df)} rows")

    # 2. ì „ì²˜ë¦¬
    scaler = MinMaxScaler()
    encoder = LabelEncoder()
    X_data = scaler.fit_transform(full_df[FEATURE_COLS])
    y_data = encoder.fit_transform(full_df['key_pressed'].astype(str))
    
    X_seq, y_seq = create_sequences(X_data, y_data, SEQ_LENGTH)
    
    X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=True, random_state=42)

    # pin_memory=True: CPU -> GPU ì „ì†¡ ì†ë„ í–¥ìƒ
    train_dataset = MapleDataset(X_train, y_train)
    val_dataset = MapleDataset(X_val, y_val)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True, 
        num_workers=NUM_WORKERS, 
        pin_memory=True,
        persistent_workers=True # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìœ ì§€
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS, 
        pin_memory=True,
        persistent_workers=True
    )

    # 3. ëª¨ë¸ ì„¤ì •
    device = torch.device("cuda")
    input_size = len(FEATURE_COLS)
    num_classes = len(encoder.classes_)
    
    model = LSTMModel(
        input_size, 
        hidden_size = 256, 
        num_layers = 3, 
        num_classes = num_classes, 
        dropout=0.4
    ).to(device)
    
    # [ìµœì í™”] PyTorch 2.0 ì»´íŒŒì¼ (ê°€ëŠ¥í•˜ë©´ ì ìš©)
    try:
        model = torch.compile(model)
        print("âš¡ Torch.compile ì ìš© ì™„ë£Œ (ì†ë„ í–¥ìƒ)")
    except: pass

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)
    
    # AMP Scaler
    scaler_amp = torch.cuda.amp.GradScaler(enabled=USE_AMP)

    # 4. í•™ìŠµ ë£¨í”„
    best_loss = float('inf')
    patience_curr = 0
    train_hist, val_hist = [], []

    print("\nğŸ”¥ í•™ìŠµ ì‹œì‘...")
    for epoch in range(EPOCHS):
        model.train()
        run_loss = 0.0
        correct = 0
        total = 0
        
        # TQDMìœ¼ë¡œ ì§„í–‰ìƒí™© í‘œì‹œ
        pbar = tqdm(train_loader, desc=f"Ep {epoch+1}", leave=False)
        for inputs, labels in pbar:
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # Mixed Precision Forward
            with torch.cuda.amp.autocast(enabled=USE_AMP):
                outputs = model(inputs)
                loss = criterion(outputs, labels)
            
            # Scaled Backward
            scaler_amp.scale(loss).backward()
            scaler_amp.step(optimizer)
            scaler_amp.update()
            
            run_loss += loss.item()
            _, pred = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (pred == labels).sum().item()
            
        avg_train_loss = run_loss / len(train_loader)
        train_acc = 100 * correct / total
        train_hist.append(avg_train_loss)

        # Validation
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                with torch.cuda.amp.autocast(enabled=USE_AMP):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, pred = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (pred == labels).sum().item()
        
        avg_val_loss = val_loss / len(val_loader)
        val_acc = 100 * correct / total
        val_hist.append(avg_val_loss)

        print(f"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} ({train_acc:.1f}%) | Val Loss={avg_val_loss:.4f} ({val_acc:.1f}%)")

        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            patience_curr = 0
            # ì €ì¥
            save_dict = {
                'model_state': model.state_dict(), # compileëœ ëª¨ë¸ì€ unwrap í•„ìš”í•  ìˆ˜ ìˆìŒ
                'scaler': scaler,
                'encoder': encoder,
                'feature_cols': FEATURE_COLS,
                'seq_length': SEQ_LENGTH,
                'val_acc': val_acc
            }
            # torch.compile ì‚¬ìš© ì‹œ state_dict í‚¤ ì ‘ë‘ì‚¬ ì²˜ë¦¬ ë“± ì£¼ì˜ í•„ìš”í•˜ë‚˜ 
            # ë‹¨ìˆœ ì €ì¥ì—” ë¬¸ì œ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŒ. ì—ëŸ¬ ì‹œ ._orig_mod ì‚¬ìš©
            torch.save(save_dict, MODEL_SAVE_PATH)
        else:
            patience_curr += 1
            if patience_curr >= PATIENCE:
                print("ğŸ›‘ Early Stopping")
                break
                
    # ê·¸ë˜í”„
    plt.plot(train_hist, label='Train')
    plt.plot(val_hist, label='Val')
    plt.legend(); plt.savefig('train_boost_result.png')
    print("âœ… ì™„ë£Œ.")

if __name__ == "__main__":
    # ìœˆë„ìš° ë©€í‹°í”„ë¡œì„¸ì‹± ì—ëŸ¬ ë°©ì§€
    multiprocessing.freeze_support()
    train()