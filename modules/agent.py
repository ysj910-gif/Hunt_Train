import torch
import numpy as np
import pandas as pd
import joblib
from collections import deque
from modules.model import LSTMModel
from modules.rune_solver import PhysicsLearner
from modules.navigator import TacticalNavigator  # [í•„ìˆ˜] modules/navigator.py ìƒì„± í•„ìš”
from platform_manager import PlatformManager

class BotAgent:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ¤– Agent Device: {self.device}")

        self.lstm_model = None
        self.rf_model = None
        self.scaler = None
        self.encoder = None
        
        self.action_queue = deque()
        self.seq_length = 10
        self.history = deque(maxlen=self.seq_length)
        
        # ê¸°ë³¸ ì»¬ëŸ¼ ì •ì˜ (ë¡œë“œ ì‹œ ë®ì–´ì¨ì§)
        self.feature_cols = ['player_x', 'player_y', 'entropy', 'platform_id', 'ult_ready', 'sub_ready']

        # [ì‹ ê·œ] ììœ¨ ì£¼í–‰ ë° ì „ìˆ  ëª¨ë“ˆ
        self.pm = PlatformManager()
        self.physics = PhysicsLearner()
        # ë¬¼ë¦¬ ì—”ì§„ ë¡œë“œ (ì‹¤íŒ¨í•´ë„ ì¹˜ëª…ì ì´ì§€ ì•Šë„ë¡ try-except ì²˜ë¦¬ ê¶Œì¥)
        try:
            self.physics.load_model("physics_hybrid_model.pth")
        except:
            print("âš ï¸ ë¬¼ë¦¬ ì—”ì§„ ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë„¤ë¹„ê²Œì´ì…˜ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        self.navigator = TacticalNavigator(self.pm, self.physics)
        self.mode = "HYBRID" # HYBRID(LSTM+Nav) / AUTO(Nav Only)
        
        self.last_kill_count = 0

    def load_lstm(self, file_path):
        """LSTM ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            checkpoint = torch.load(file_path, map_location=self.device)
            self.scaler = checkpoint['scaler']
            self.encoder = checkpoint['encoder']
            self.feature_cols = checkpoint.get('feature_cols', self.feature_cols)
            self.seq_length = checkpoint.get('seq_length', 10)
            
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ
            input_size = checkpoint.get('input_size', len(self.feature_cols))
            hidden_size = checkpoint.get('hidden_size', 128)
            num_layers = checkpoint.get('num_layers', 2)
            num_classes = checkpoint.get('num_classes', 10)
            future_steps = checkpoint.get('future_steps', 1)
            dropout = checkpoint.get('dropout', 0)

            self.lstm_model = LSTMModel(
                input_size, hidden_size, num_layers, num_classes, future_steps, dropout
            ).to(self.device)
            
            self.lstm_model.load_state_dict(checkpoint['model_state'])
            self.lstm_model.eval()
            
            self.history = deque(maxlen=self.seq_length)
            return True, f"LSTM Loaded (Seq:{self.seq_length}, Future:{future_steps})"
        except Exception as e:
            return False, f"LSTM Error: {str(e)}"

    def load_rf(self, file_path):
        """Random Forest ëª¨ë¸ ë¡œë“œ (í˜¸í™˜ì„± ìœ ì§€ìš©)"""
        try:
            self.rf_model = joblib.load(file_path)
            return True, "RF Loaded"
        except Exception as e:
            return False, str(e)

    def reset_history(self):
        self.history.clear()
        self.action_queue.clear()
        self.last_kill_count = 0

    def on_map_change(self, map_json_path):
        """ë§µ ë³€ê²½ ì‹œ ë„¤ë¹„ê²Œì´í„° ì¬ì„¤ì •"""
        self.pm.load_platforms(map_json_path)
        self.navigator.build_graph()

    def get_action(self, px, py, entropy, pid, ult_ready, sub_ready, dist_left=0, dist_right=0, current_kill_count=0):
        """
        ë´‡ì˜ í–‰ë™ ê²°ì • (LSTM + Tactical Navigator)
        """
        # 1. í‚¬ ë³´ìƒ ì—…ë°ì´íŠ¸ (ë„¤ë¹„ê²Œì´í„°ì—ê²Œ ì •ë³´ ì œê³µ)
        kill_diff = max(0, current_kill_count - self.last_kill_count)
        self.last_kill_count = current_kill_count
        
        if kill_diff > 0:
            self.navigator.update_combat_stats(px, py, kill_diff)

        # 2. í í™•ì¸ (ì´ë¯¸ ê³„íšëœ í–‰ë™ ìˆ˜í–‰)
        if self.action_queue:
            return self.action_queue.popleft(), f"Seq({len(self.action_queue)})"

        # 3. LSTM ì¶”ë¡  ì¤€ë¹„
        lstm_action = "None"
        lstm_status = "Wait"
        
        if self.lstm_model:
            try:
                # ë°ì´í„° ì „ì²˜ë¦¬
                input_data = {
                    'player_x': px, 'player_y': py, 'entropy': entropy, 
                    'platform_id': pid, 'ult_ready': ult_ready, 'sub_ready': sub_ready,
                    'dist_left': dist_left, 'dist_right': dist_right, # gui.pyì—ì„œ ë„˜ê²¨ì£¼ëŠ” ê±°ë¦¬
                    # ì•„ë˜ ê°’ë“¤ì€ ê¸°ë³¸ê°’ 0 (gui.pyì—ì„œ ê³„ì‚° ì•ˆ í•˜ë¯€ë¡œ)
                    'inv_dist_up': 0, 'inv_dist_down': 0, 'inv_dist_left': 0, 'inv_dist_right': 0,
                    'corner_tl': 0, 'corner_tr': 0, 'corner_bl': 0, 'corner_br': 0
                }
                
                df = pd.DataFrame([input_data])
                for col in self.feature_cols:
                    if col not in df.columns: df[col] = 0
                
                feats_scaled = self.scaler.transform(df[self.feature_cols])
                self.history.append(feats_scaled[0])

                if len(self.history) == self.seq_length:
                    inp = torch.FloatTensor(np.array([self.history])).to(self.device)
                    with torch.no_grad():
                        out = self.lstm_model(inp) # Output: (1, Future, Classes)
                        _, preds = torch.max(out, 2)
                        preds = preds.squeeze(0).cpu().numpy() # (Future,)
                        
                        # ë¯¸ë˜ ì˜ˆì¸¡ í–‰ë™ë“¤ì„ íì— ë‹´ìŒ
                        actions = self.encoder.inverse_transform(preds)
                        self.action_queue.extend(actions)
                        
                        lstm_action = self.action_queue.popleft()
                        lstm_status = "LSTM"
            except Exception as e:
                print(f"Agent Action Error: {e}")

        # 4. [í•µì‹¬] í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ (ë„¤ë¹„ê²Œì´í„° ê°œì…)
        nav_action, nav_msg = self.navigator.get_move_decision(px, py)
        
        # A. ìº í•‘ ëª¨ë“œì¼ ë•Œ (ëª…ë‹¹ ìë¦¬ ì‚¬ìˆ˜)
        if "Camping" in nav_msg:
            # ê¿€ìë¦¬ì— ìˆìœ¼ë¯€ë¡œ ì´ë™(Left/Right)ì€ ìì œí•˜ê³ , ê³µê²©/ì„¤ì¹˜ê¸° ìœ„ì£¼ë¡œ ìˆ˜í–‰
            if lstm_action != "None" and ("left" in lstm_action or "right" in lstm_action):
                # LSTMì´ ì´ë™í•˜ë ¤ê³  í•˜ë©´ ë¬´ì‹œ (ìº í•‘ ìœ ì§€)
                return "None", "Camping(Hold)"
            
            # ê³µê²©ì´ë‚˜ ìŠ¤í‚¬ ì‚¬ìš©ì´ë©´ LSTM ë”°ë¦„ (ì•„ë‹ˆë©´ ëœë¤ ê³µê²©)
            if lstm_action != "None":
                return lstm_action, "Camping(Act)"
            else:
                # í•  ê²Œ ì—†ìœ¼ë©´ ë„¤ë¹„ê²Œì´í„°ê°€ 'None'ì„ ì¤˜ì„œ ëŒ€ê¸°í•˜ê±°ë‚˜, ê´‘ì—­ê¸° ì¿¨íƒ€ì„ ì²´í¬ í›„ ì‚¬ìš©
                if sub_ready == 1: return "q", "Camp+Atk" # ì˜ˆ: Qê°€ ê´‘ì—­ê¸°ë¼ë©´
                return "None", "Camping"

        # B. íƒìƒ‰/ì´ë™ ëª¨ë“œì¼ ë•Œ
        # LSTMì´ ë©ë•Œë¦¬ê±°ë‚˜(None), í™•ì‹ ì´ ì—†ê±°ë‚˜, AUTO ëª¨ë“œì¼ ë•Œ ë„¤ë¹„ê²Œì´í„°ê°€ ê¸¸ ì•ˆë‚´
        if self.mode == "AUTO" or lstm_action == "None" or not self.lstm_model:
            if nav_action != "None":
                # ì´ë™í•˜ë©´ì„œ ê³µê²© ì„ê¸° (Nav+Atk)
                if sub_ready == 1: 
                    return f"{nav_action}+q", "Nav+Atk"
                return nav_action, nav_msg
            
        return lstm_action, lstm_status