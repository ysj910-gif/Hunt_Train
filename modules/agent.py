import torch
import numpy as np
import pandas as pd
import joblib
import random
from collections import deque
from modules.model import LSTMModel

class BotAgent:
    def __init__(self):
        # ì¥ì¹˜ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ¤– Agent Device: {self.device}")

        # ëª¨ë¸ ë° ìƒíƒœ ë³€ìˆ˜
        self.lstm_model = None
        self.rf_model = None
        self.scaler = None
        self.encoder = None
        
        # ì‹œí€€ìŠ¤ í (ë¯¸ë˜ í–‰ë™ ê³„íš)
        self.action_queue = deque()
        
        # ê¸°ì–µ ì €ì¥ì†Œ (LSTMìš©)
        self.seq_length = 10
        self.history = deque(maxlen=self.seq_length)
        
        # ì…ë ¥ íŠ¹ì„± ì»¬ëŸ¼ (ê¸°ë³¸ê°’)
        self.feature_cols = ['player_x', 'player_y', 'entropy', 'platform_id', 'ult_ready', 'sub_ready']

    def load_lstm(self, file_path):
        """LSTM ëª¨ë¸ ë¡œë“œ"""
        try:
            checkpoint = torch.load(file_path, map_location=self.device)
            
            self.scaler = checkpoint['scaler']
            self.encoder = checkpoint['encoder']
            self.feature_cols = checkpoint.get('feature_cols', self.feature_cols)
            
            # ì‹œí€€ìŠ¤ ê¸¸ì´ ì—…ë°ì´íŠ¸
            self.seq_length = checkpoint.get('seq_length', 10)
            self.history = deque(maxlen=self.seq_length)
            
            # ëª¨ë¸ ìƒì„±
            self.lstm_model = LSTMModel(
                input_size=checkpoint.get('input_size', 6),
                hidden_size=checkpoint.get('hidden_size', 128),
                num_layers=checkpoint.get('num_layers', 2),
                num_classes=checkpoint.get('num_classes', 10),
                future_steps=checkpoint.get('future_steps', 1),
                dropout=checkpoint.get('dropout', 0)
            ).to(self.device)
            
            self.lstm_model.load_state_dict(checkpoint['model_state'])
            self.lstm_model.eval()
            return True, f"LSTM Loaded (Seq: {self.seq_length})"
        except Exception as e:
            return False, str(e)

    # [â˜…ì¶”ê°€] ì´ í•¨ìˆ˜ê°€ ì—†ì–´ì„œ ì—ëŸ¬ê°€ ë‚¬ì—ˆìŠµë‹ˆë‹¤.
    def load_rf(self, file_path):
        """Random Forest ëª¨ë¸ ë¡œë“œ"""
        try:
            self.rf_model = joblib.load(file_path)
            return True, "RF Loaded"
        except Exception as e:
            return False, str(e)

    def reset_history(self):
        self.history.clear()
        self.action_queue.clear()

    def get_action(self, px, py, entropy, pid, ult_ready, sub_ready, dist_left=0, dist_right=0):
        """í˜„ì¬ ìƒíƒœë¥¼ ë°›ì•„ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •"""
        
        # 1. íì— ê³„íšëœ í–‰ë™ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
        if self.action_queue:
            return self.action_queue.popleft(), f"Seq({len(self.action_queue)})"

        if not self.lstm_model:
            return "None", "No Model"

        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        try:
            input_data = {
                'player_x': px, 'player_y': py, 'entropy': entropy, 
                'platform_id': pid, 'ult_ready': ult_ready, 'sub_ready': sub_ready,
                'dist_left': dist_left, 'dist_right': dist_right,
                # ë§Œì•½ í•™ìŠµ ë•Œ inv_dist ë“± ê³ ê¸‰ íŠ¹ì„±ì„ ì¼ë‹¤ë©´ ì—¬ê¸°ì„œë„ ê³„ì‚°í•´ì„œ ë„£ì–´ì¤˜ì•¼ í•¨ (ê°„ì†Œí™”ë¥¼ ìœ„í•´ ìƒëµ ê°€ëŠ¥í•˜ë‚˜ ì„±ëŠ¥ ì˜í–¥ ìˆìŒ)
                # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ 0ìœ¼ë¡œ ì±„ì›Œì„œ ì—ëŸ¬ ë°©ì§€
                'inv_dist_up': 0, 'inv_dist_down': 0, 'inv_dist_left': 0, 'inv_dist_right': 0,
                'corner_tl': 0, 'corner_tr': 0, 'corner_bl': 0, 'corner_br': 0
            }
            
            df = pd.DataFrame([input_data])
            
            # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸° & ì—†ëŠ” ì»¬ëŸ¼ 0 ì±„ìš°ê¸°
            for col in self.feature_cols:
                if col not in df.columns:
                    df[col] = 0
            
            # ìŠ¤ì¼€ì¼ë§
            feats_scaled = self.scaler.transform(df[self.feature_cols])
            self.history.append(feats_scaled[0])
            
        except Exception as e:
            print(f"Agent Data Error: {e}")
            return "None", "Error"

        action_name = "None"
        debug_msg = ""

        # 3. ê²°ì • ë¡œì§
        if len(self.history) == self.seq_length:
            inp = torch.FloatTensor(np.array([self.history])).to(self.device)
            with torch.no_grad():
                out = self.lstm_model(inp)
                _, preds = torch.max(out, 2)
                preds = preds.squeeze(0).cpu().numpy()
                
                actions = self.encoder.inverse_transform(preds)
                self.action_queue.extend(actions)
                
                action_name = self.action_queue.popleft()
                debug_msg = "LSTM(New)"
        else:
            action_name = "None"
            debug_msg = f"Wait({len(self.history)})"

        return action_name, debug_msg